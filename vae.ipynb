{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3cb01e-e8fd-45c4-8225-2587da55ef06",
   "metadata": {},
   "source": [
    "Variational Autoencoder test\n",
    "\n",
    "Python version: x <br>\n",
    "PyTorch version: y <br>\n",
    "Numpy version: z <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1a30b3c5-5444-4ec8-a07b-161a2ab9b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "image_size = (64, 64)\n",
    "image_vector_dim = image_size[0] * image_size[1]\n",
    "\n",
    "object_size = (8, 8)\n",
    "\n",
    "input_dimension = image_size[0] * image_size[1]\n",
    "hidden_dimension_encoder = 1000\n",
    "latent_dimension = 2\n",
    "hidden_dimension_decoder = 1000\n",
    "output_dimension = image_size[0] * image_size[1]\n",
    "\n",
    "dataset_size = 5000\n",
    "batch_size = 10\n",
    "epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d4c92c62-dad7-4d9f-b9f4-0194b1f3040a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RandomImageDataset(Dataset):\n",
    "    def __init__(self, dataset_size: int=1024, image_size: Tuple[int, int]=(128,128), object_size: Tuple[int, int]=(32,32)):\n",
    "        self.dataset_size = dataset_size\n",
    "        self.image_size = image_size\n",
    "        self.object_size = object_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.dataset_size\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        z = torch.zeros(self.image_size)\n",
    "        o = torch.ones(self.object_size)\n",
    "\n",
    "        object_x_min = 0\n",
    "        object_x_max = self.image_size[0] - self.object_size[0]\n",
    "\n",
    "        object_y_min = 0\n",
    "        object_y_max = self.image_size[0] - self.object_size[0]\n",
    "\n",
    "        object_x = np.random.randint(object_x_min, object_x_max)\n",
    "        object_y = np.random.randint(object_y_min, object_y_max)\n",
    "\n",
    "        z[object_x:(object_x+self.object_size[0]), object_y:(object_y+self.object_size[0])] = o        \n",
    "        return z\n",
    "\n",
    "dataset_test = RandomImageDataset(image_size = image_size)\n",
    "plt.imshow(dataset_test.__getitem__(123), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Test image')\n",
    "plt.show()\n",
    "\n",
    "dataset_training = RandomImageDataset(dataset_size=dataset_size, image_size=image_size, object_size=object_size)\n",
    "dataset_testing = RandomImageDataset(dataset_size=dataset_size, image_size=image_size, object_size=object_size)\n",
    "\n",
    "dataloader_training = DataLoader(dataset_training, batch_size=batch_size)\n",
    "dataloader_testing = DataLoader(dataset_testing, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7c336f8d-129b-4fa7-816d-27ee9d53782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dimension: int, hidden_dimension: int, latent_dimension: int):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dimension = input_dimension\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.latent_dimension = latent_dimension\n",
    "\n",
    "        self.fc0 = torch.nn.Linear(input_dimension, hidden_dimension)\n",
    "        self.fc1 = torch.nn.Linear(hidden_dimension, hidden_dimension)\n",
    "        self.mean = torch.nn.Linear(hidden_dimension, latent_dimension)\n",
    "        self.var = torch.nn.Linear(hidden_dimension, latent_dimension)\n",
    "\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        t = self.fc0(data)\n",
    "        t = self.lrelu(t)\n",
    "        t = self.fc1(t)\n",
    "        t = self.lrelu(t)\n",
    "        mean = self.mean(t)\n",
    "        var = self.var(t)\n",
    "\n",
    "        return mean, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d8e3319b-0baf-4111-9461-61c6669d8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, latent_dimension, hidden_dimension, output_dimension):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.latent_dimension = latent_dimension\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.output_dimension = output_dimension\n",
    "\n",
    "        self.fc0 = torch.nn.Linear(latent_dimension, hidden_dimension)\n",
    "        self.fc1 = torch.nn.Linear(hidden_dimension, hidden_dimension)\n",
    "        self.output = torch.nn.Linear(hidden_dimension, output_dimension)\n",
    "\n",
    "        self.lrelu = torch.nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        t = self.fc0(data)\n",
    "        t = self.lrelu(t)\n",
    "\n",
    "        t = self.fc1(t)\n",
    "        t = self.lrelu(t)\n",
    "\n",
    "        t = torch.sigmoid(self.output(t))\n",
    "\n",
    "        return t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa6b7a-e4de-4a0c-8297-8fa19a1268b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  loss: 1434380.7954101562\n",
      "epoch 1  loss: 970684.5579833984\n",
      "epoch 2  loss: 823109.7811279297\n",
      "epoch 3  loss: 779155.6024169922\n",
      "epoch 4  loss: 741966.1359863281\n",
      "epoch 5  loss: 685163.4354858398\n",
      "epoch 6  loss: 643267.3712768555\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "class VariationalAutoencoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dimension, hidden_dimension_encoder, latent_dimension, hidden_dimension_decoder, output_dimension):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder(input_dimension = input_dimension, hidden_dimension = hidden_dimension_encoder, latent_dimension = latent_dimension)\n",
    "        self.decoder = Decoder(latent_dimension = latent_dimension, hidden_dimension = hidden_dimension_decoder, output_dimension = output_dimension)\n",
    "\n",
    "        \n",
    "    def forward(self, data):\n",
    "        mean, var = self.encoder(data)\n",
    "        e = torch.randn_like(var).to(DEVICE)\n",
    "        z = mean + torch.exp(0.5* var) * e\n",
    "\n",
    "        data_ = self.decoder(z)\n",
    "\n",
    "        return data_, mean, var\n",
    "\n",
    "vae = VariationalAutoencoder(input_dimension, hidden_dimension_encoder, latent_dimension, hidden_dimension_decoder, output_dimension)\n",
    "vae.to(DEVICE)\n",
    "\n",
    "# loss\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "def vae_loss(data, data_, mean, var):\n",
    "    loss = torch.nn.functional.binary_cross_entropy(data_, data, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1+ var - mean.pow(2) - var.exp())\n",
    "    return loss + KLD\n",
    "    \n",
    "optimizer = Adam(vae.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "vae.train()\n",
    "\n",
    "for e in range(epochs):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for data in dataloader_training:\n",
    "        data = data.view(batch_size, image_vector_dim)\n",
    "        data = data.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data_, mean, var = vae(data)\n",
    "        loss = vae_loss(data, data_, mean, var)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch\",e,\" loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb802ee-7f13-4fc0-9011-91c1bd1c9c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "\n",
    "vae.eval()\n",
    "\n",
    "for data in dataloader_testing:\n",
    "    data = data.view(batch_size, image_vector_dim)\n",
    "    \n",
    "    data=data.to(DEVICE)\n",
    "\n",
    "    data_, mean, variance = vae(data)\n",
    "    data_ = data_.view(batch_size, image_size[0], image_size[1])\n",
    "    for i in range(batch_size):\n",
    "        im = data_[i]\n",
    "        im_np = im.cpu().detach().numpy()\n",
    "        plt.imshow(im_np, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title('Test image')\n",
    "        plt.show()\n",
    "    print(data_.shape)\n",
    "    input('jee')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047598d-208d-447b-8884-314f062a1d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
